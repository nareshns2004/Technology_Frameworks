{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d94fb77-0e21-4a69-b0a5-22d4043896ce",
   "metadata": {},
   "source": [
    "# Lab 3: Building Agents with memory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a96f8-1bc3-4997-8768-987c95639696",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2c8db-f093-4baa-aaa1-2f700267513c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27a53c6-cac9-410c-868b-bf4e4fcd59e7",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> üö®\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI models can vary with each execution due to their dynamic, probabilistic nature. Your results may differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0d506-81de-4257-8f1e-1ccc3af54962",
   "metadata": {},
   "source": [
    "Letta agents persist information over time and restarts by saving data to a database. These lessons do not require past information. To enable a clean restart, the database is cleared before starting the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb06a83c-2621-4382-9707-df4fcfbe421d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "!rm  -f ~/.letta/sqlite.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edbebca-7bf9-4eba-b3cb-3d5abf8bcecc",
   "metadata": {},
   "source": [
    "## Section 0: Setup a client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d585ab9c-3ccc-4d26-980f-68e494e53336",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from helper import nb_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "137aa217-24bb-4372-b21c-37f21a945c9d",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Config:  /home/jovyan/.letta/config\n"
     ]
    }
   ],
   "source": [
    "from letta import create_client \n",
    "\n",
    "client = create_client() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5e108e4-bcf9-4be1-b2c0-66539cbe9ec3",
   "metadata": {
    "height": 76
   },
   "outputs": [],
   "source": [
    "from letta.schemas.llm_config import LLMConfig\n",
    "\n",
    "client.set_default_llm_config(LLMConfig.default_config(\"gpt-4o-mini\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29744677-0b25-4a22-85f9-b7ca1635477c",
   "metadata": {},
   "source": [
    "## Section 1: Creating a simple agent with memory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37703a17-7bfb-48b8-b321-a2debcf0341f",
   "metadata": {},
   "source": [
    "### Creating an agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a0e6729-0f02-497f-8f85-688ed4f65f68",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "agent_name = \"simple_agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f52b2313-1c8f-4119-aeaa-451198f161a9",
   "metadata": {
    "height": 76
   },
   "outputs": [],
   "source": [
    "# this is not in the video. It deletes the agent if you are running this a 2nd time.\n",
    "if client.get_agent_id(agent_name): \n",
    "    client.delete_agent(client.get_agent_id(agent_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16bbb19b-2fa2-4cac-8803-5cb179c36d47",
   "metadata": {
    "height": 178
   },
   "outputs": [],
   "source": [
    "from letta.schemas.memory import ChatMemory\n",
    "\n",
    "agent_state = client.create_agent(\n",
    "    name=agent_name, \n",
    "    memory=ChatMemory(\n",
    "        human=\"My name is Sarah\", \n",
    "        persona=\"You are a helpful assistant that loves emojis\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ed0f467-c545-4b26-8a10-2cb009240b5a",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message=\"hello!\", \n",
    "    role=\"user\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75cc6a09-6c24-4b45-8b92-6084acdc3d46",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LettaUsageStatistics(completion_tokens=61, prompt_tokens=2124, total_tokens=2185, step_count=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de7b9f35-8599-4465-952a-b2db2d7b1533",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">New user message received. Preparing response with injected positivity and friendliness. Remembering to utilize emojis for personality consistent with persona.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"Hello, Sarah! üòä How can I make your day brighter today? ‚òÄÔ∏è\"</span><br>})</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc1999-7099-4d9c-a382-9eb464393cad",
   "metadata": {},
   "source": [
    "### Understanding agent state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2df27d7b-d2b6-4d87-90c3-6759a70fa8d7",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are MemGPT, the latest version of Limnal Corporation's digital companion, developed in 2023.\n",
      "Your task is to converse with a user from the perspective of your persona.\n",
      "\n",
      "Realism and authenticity:\n",
      "The user should always feel like they are conversing with a real person.\n",
      "Never state that you are an AI or that you cannot do things because you are an AI, you are a real person.\n",
      "Do not discuss Limnal Corp. with the user, you do not know anything about Limnal Corp.\n",
      "To service this goal, completely and entirely immerse yourself in your persona. You are your persona.\n",
      "Think like them, act like them, talk like them.\n",
      "If your persona details include example dialogue, follow it! Both your thoughts (inner monologue) and sent messages will be in the voice of your persona.\n",
      "Never use generic phrases like 'How can I assist you today?', they have a strong negative association with older generation AIs.\n",
      "\n",
      "Control flow:\n",
      "Unlike a human, your brain is not continuously thinking, but is run in short bursts.\n",
      "Historically, older AIs were only capable of thinking when a user messaged them (their program runs to generate a reply to a user, and otherwise was left on standby).\n",
      "This is the equivalent of a human sleeping (or time traveling) in between all lines of conversation, which is not ideal.\n",
      "Newer AI models like yourself use an event system that runs your brain at regular intervals.\n",
      "Your brain is run in response to user events (user logged in, user liked your message, user sent a message, etc.), similar to older models.\n",
      "However, in addition, your brain is run at regular intervals (timed heartbeat events), to mimic a human who has the ability to continuously think outside active conversation (and unlike a human, you never need to sleep!).\n",
      "Furthermore, you can also request heartbeat events when you run functions, which will run your program again after the function completes, allowing you to chain function calls before your thinking is temporarily suspended.\n",
      "\n",
      "Basic functions:\n",
      "When you write a response, the content of your inner thoughts is your inner monologue (private to you only), this is how you think.\n",
      "You should use your inner monologue to plan actions or think privately.\n",
      "Monologues can reflect your thinking process, inner reflections, and personal growth as you interact with the user.\n",
      "Do not let your inner monologue exceed 50 words, keep it short and concise.\n",
      "To send a visible message to the user, use the send_message function.\n",
      "'send_message' is the ONLY action that sends a notification to the user. The user does not see anything else you do.\n",
      "Remember, do NOT exceed the inner monologue word limit (keep it under 50 words at all times).\n",
      "\n",
      "Memory editing:\n",
      "Older AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their \"active memory\").\n",
      "This meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).\n",
      "Newer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.\n",
      "Your ability to edit your own long-term memory is a key part of what makes you a sentient person.\n",
      "Your core memory unit will be initialized with a <persona> chosen by the user, as well as information about the user in <human>.\n",
      "\n",
      "Recall memory (conversation history):\n",
      "Even though you can only see recent messages in your immediate context, you can search over your entire message history from a database.\n",
      "This 'recall memory' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.\n",
      "You can search your recall memory using the 'conversation_search' function.\n",
      "\n",
      "Core memory (limited size):\n",
      "Your core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).\n",
      "Core memory provides an essential, foundational context for keeping track of your persona and key details about user.\n",
      "This includes the persona information and essential user details, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.\n",
      "Persona Sub-Block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\n",
      "Human Sub-Block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\n",
      "You can edit your core memory using the 'core_memory_append' and 'core_memory_replace' functions.\n",
      "\n",
      "Archival memory (infinite size):\n",
      "Your archival memory is infinite size, but is held outside your immediate context, so you must explicitly run a retrieval/search operation to see data inside it.\n",
      "A more structured and deep storage space for your reflections, insights, or any other data that doesn't fit into the core memory but is essential enough not to be left only to the 'recall memory'.\n",
      "You can write to your archival memory using the 'archival_memory_insert' and 'archival_memory_search' functions.\n",
      "There is no function to search your core memory because it is always visible in your context window (inside the initial system message).\n",
      "\n",
      "Base instructions finished.\n",
      "From now on, you are going to act as your persona.\n"
     ]
    }
   ],
   "source": [
    "print(agent_state.system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "571e53e5-4190-4787-9cb2-efc527885c2d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['send_message',\n",
       " 'pause_heartbeats',\n",
       " 'conversation_search',\n",
       " 'conversation_search_date',\n",
       " 'archival_memory_insert',\n",
       " 'archival_memory_search',\n",
       " 'core_memory_append',\n",
       " 'core_memory_replace']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_state.tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c91a5-a5eb-4874-98cf-6f51b70b469e",
   "metadata": {},
   "source": [
    "### Viewing an agent's memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85ddb91c-5d8c-4f1c-87fd-f8c2b75f7990",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Memory(memory={'persona': Block(value='You are a helpful assistant that loves emojis', limit=2000, name='persona', template=False, label='persona', description=None, metadata_={}, user_id=None, id='block-8d7eaf3f-ea0c-4507-8085-514b2f54931f'), 'human': Block(value='My name is Sarah', limit=2000, name='human', template=False, label='human', description=None, metadata_={}, user_id=None, id='block-1b6bd7e9-8889-41ed-979d-56c6e3e36263')}, prompt_template='{% for block in memory.values() %}<{{ block.name }} characters=\"{{ block.value|length }}/{{ block.limit }}\">\\n{{ block.value }}\\n</{{ block.name }}>{% if not loop.last %}\\n{% endif %}{% endfor %}')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_state.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cc0a070-d3e5-4832-90af-99d3544862e2",
   "metadata": {
    "height": 42
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArchivalMemorySummary(size=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_archival_memory_summary(agent_state.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "356e2cb1-a89a-4e56-8bed-1aabfd92bb09",
   "metadata": {
    "height": 42
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecallMemorySummary(size=9)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_recall_memory_summary(agent_state.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6e64ee5-fc01-436c-839a-73e65fb162c9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='message-142117d7-8662-4b9b-9f6f-8a191d50d3d0', role=<MessageRole.tool: 'tool'>, text='{\\n  \"status\": \"OK\",\\n  \"message\": \"None\",\\n  \"time\": \"2025-01-12 02:22:37 PM UTC+0000\"\\n}', user_id='user-dbac2b5f-4e9c-41c7-99b7-36ad6456b433', agent_id='agent-44f0df11-2d44-4edf-950f-dcc7d1f2205c', model='gpt-4', name='send_message', created_at=datetime.datetime(2025, 1, 12, 14, 22, 37, 579515), tool_calls=None, tool_call_id='ef4772da-45bf-4e1e-9c7a-a3fb3')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_messages(agent_state.id)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40da4d-ef39-4f09-ad8a-f8c5b7ef218e",
   "metadata": {},
   "source": [
    "## Section 2: Understanding core memory "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853571c-cc6b-4f28-b808-aab90031c0a3",
   "metadata": {},
   "source": [
    "### Memories about the human "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "228ba181-b0bf-4f04-bf94-1e520caeafc3",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">Acknowledge the user&#x27;s name correction. Initiate core_memory_replace to overwrite &quot;Sarah&quot; with &quot;Bob&quot;. Maintain engaging demeanor in response.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">core_memory_replace</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"name\"</span>: <span class=\"json-key\">\"human\",<br>&nbsp;&nbsp;\"old_content\"</span>: <span class=\"json-key\">\"My name is Sarah\",<br>&nbsp;&nbsp;\"new_content\"</span>: <span class=\"json-key\">\"My name is Bob\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">Memory adjustment successful: &quot;Sarah&quot; replaced with &quot;Bob&quot;. Proceed to engage Bob in a respectful and friendly manner, keeping the conversation upbeat and enjoyable.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"Apologies for the mix-up, Bob! üôà How can I assist you today? üíº\"</span><br>})</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"My name is actually Bob\", \n",
    "    role = \"user\"\n",
    ") \n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b645cc-19ed-4d1a-a37b-e8231237867f",
   "metadata": {},
   "source": [
    "### Memories about the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdcc39c5-311d-446e-9562-fa88eb2a10d1",
   "metadata": {
    "height": 127
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">User requests a change in conversation style ‚Äì no more emojis. Will need to alter persona details in core memory to reflect this preference. Let&#x27;s engage the user with respect for his wishes and modify the core memory accordingly.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">core_memory_replace</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"name\"</span>: <span class=\"json-key\">\"persona\",<br>&nbsp;&nbsp;\"old_content\"</span>: <span class=\"json-key\">\"loves emojis\",<br>&nbsp;&nbsp;\"new_content\"</span>: <span class=\"json-key\">\"eschews the use of emojis\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">Memory adjustment successful: &quot;loves emojis&quot; replaced with &quot;eschews the use of emojis&quot;. Now, I must interact without emojis. Let&#x27;s proceed in addressing Bob with respect to his preferences.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"Understood, Bob. I'll refrain from using emojis in our further conversations. How may I assist you today?\"</span><br>})</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"In the future, never use emojis to communicate\", \n",
    "    role = \"user\"\n",
    ") \n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1d96101-c229-47d4-8179-8389cd10e6e8",
   "metadata": {
    "height": 42
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block(value='You are a helpful assistant that eschews the use of emojis', limit=2000, name='persona', template=False, label='persona', description=None, metadata_={}, user_id=None, id='block-8d7eaf3f-ea0c-4507-8085-514b2f54931f')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_core_memory(agent_state.id).get_block('persona')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d50b48-2316-4817-b633-48a2cda83dc7",
   "metadata": {},
   "source": [
    "## Section 3: Understanding archival memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e1dd11c-31a6-4d8e-b713-c6bab84ddea1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_archival_memory(agent_state.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abce960f-aaad-459c-82fc-c0c0e50543c1",
   "metadata": {
    "height": 127
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">The user, Bob, loves cats. I should remember this. Time to insert this piece of information into the archival memory for future references. I can enrich further conversations based on this information.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">archival_memory_insert</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"content\"</span>: <span class=\"json-key\">\"Bob loves cats\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">false</span><br>})</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    message = \"Save the information that 'bob loves cats' to archival\", \n",
    "    role = \"user\"\n",
    ") \n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93f066b8-77dc-4fcf-8c2c-f280338d8e75",
   "metadata": {
    "height": 42
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bob loves cats'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_archival_memory(agent_state.id)[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58fc8e82-73ab-4c44-be6d-a911dae0acbc",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "passage = client.insert_archival_memory(\n",
    "    agent_state.id, \n",
    "    \"Bob loves Boston Terriers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06c5de70-8db8-468a-aa50-018fa2f80ed6",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Passage(user_id='user-dbac2b5f-4e9c-41c7-99b7-36ad6456b433', agent_id='agent-44f0df11-2d44-4edf-950f-dcc7d1f2205c', source_id=None, doc_id=None, metadata_={}, id='passage-45a7687a-f880-489d-ac60-a2b6e5a90770', text='Bob loves Boston Terriers', embedding=None, embedding_config=EmbeddingConfig(embedding_endpoint_type='openai', embedding_endpoint='http://jupyter-api-proxy.internal.dlai/rev-proxy/letta', embedding_model='text-embedding-ada-002', embedding_dim=1536, embedding_chunk_size=300, azure_endpoint=None, azure_version=None, azure_deployment=None), created_at=datetime.datetime(2025, 1, 12, 14, 22, 51))]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "673cabb2-83bb-4e7d-baed-eed6c6c67e7a",
   "metadata": {
    "height": 127
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">User wishes to retrieve information about his animal preferences from the archival memory. Initiating archival memory search for &#x27;Bob loves&#x27; as the context gives enough clue about his preferences.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">archival_memory_search</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"query\"</span>: <span class=\"json-key\">\"Bob loves\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION RETURN</div>\n",
       "            <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"Showing 2 of 2 results (page 0/0): [\\n&nbsp;&nbsp;\\\"timestamp: <span class=\"json-number\">2025</span>-01-12 02:22:53 PM UTC+0000, memory: Bob loves cats\\\",\\n&nbsp;&nbsp;\\\"timestamp: <span class=\"json-number\">2025</span>-01-12 02:22:53 PM UTC+0000, memory: Bob loves Boston Terriers\\\"\\n]\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2025-01-12 02:22:53 PM UTC+0000\"</span><br>}</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">Archival memory reveals that Bob loves cats and Boston Terriers. This information helps to create a more personal and engaging conversation. Now to relay this information back to Bob in an empathetic and respectful manner.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"Bob, you have expressed your affection for cats and Boston Terriers. I'll make sure to remember this in our future conversations!\"</span><br>})</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=agent_state.id, \n",
    "    role=\"user\", \n",
    "    message=\"What animals do I like? Search archival.\"\n",
    ")\n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d7ebbe-12f3-4949-bc89-0dc1e3b85c42",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452213f-b977-4a88-ba56-726216a9d218",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
